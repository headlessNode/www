<h1 id="online-binary-classification">Online Binary Classification</h1>
<blockquote>
<p>Online binary classification via <a href="https://en.wikipedia.org/wiki/Stochastic_gradient_descent">Stochastic Gradient Descent</a>.</p>
</blockquote>
<section class="usage">
<h2 id="usage">Usage</h2>
<!-- eslint-disable id-length -->
<pre><code class="hljs language-javascript"><span class="hljs-keyword">var</span> onlineBinaryClassification = <span class="hljs-built_in">require</span>( <span class="hljs-string">'@stdlib/ml/online-binary-classification'</span> );
</code></pre>
<h4 id="onlinebinaryclassification-options-">onlineBinaryClassification( [options] )</h4>
<p>Creates an online linear regression model fitted via <a href="https://en.wikipedia.org/wiki/Stochastic_gradient_descent">stochastic gradient descent</a>. The module performs <a href="https://en.wikipedia.org/wiki/Tikhonov_regularization">L2 regularization</a> of the model coefficients, shrinking them towards zero by penalizing the squared <a href="https://en.wikipedia.org/wiki/Norm_(mathematics)#Euclidean_norm">euclidean norm</a> of the coefficients.</p>
<pre><code class="hljs language-javascript"><span class="hljs-keyword">var</span> model = onlineBinaryClassification();

<span class="hljs-keyword">var</span> idx;
<span class="hljs-keyword">var</span> i;
<span class="hljs-keyword">var</span> x;
<span class="hljs-keyword">var</span> y;

x = [ [ <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0.5</span> ], [ <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0.5</span> ] ];
y = [ <span class="hljs-number">-1</span>, <span class="hljs-number">1</span> ];

<span class="hljs-comment">// Iterate 500 times:</span>
<span class="hljs-keyword">for</span> ( i = <span class="hljs-number">0</span>; i &#x3C; <span class="hljs-number">500</span>; i++ ) {
    idx = i % <span class="hljs-number">2</span>;
    model.update( x[ idx ], y[ idx ] );
}
</code></pre>
<p>The function accepts the following <code>options</code>:</p>
<ul>
<li><strong>learningRate</strong>: <code>string</code> denoting the learning rate to use. Can be <code>constant</code>, <code>pegasos</code> or <code>basic</code>. Default: <code>basic</code>.</li>
<li><strong>loss</strong>: <code>string</code> denoting the loss function to use. Can be <code>hinge</code>, <code>log</code>, <code>modifiedHuber</code>, <code>perceptron</code> or <code>squaredHinge</code>. Default: <code>log</code>.</li>
<li><strong>epsilon</strong>: insensitivity parameter. Default: <code>0.1</code>.</li>
<li><strong>lambda</strong>: regularization parameter. Default: <code>1e-3</code>.</li>
<li><strong>eta0</strong>: constant learning rate. Default: <code>0.02</code>.</li>
<li><strong>intercept</strong>: <code>boolean</code> indicating whether to include an intercept. Default: <code>true</code>.</li>
</ul>
<!-- run-disable -->
<pre><code class="hljs language-javascript"><span class="hljs-keyword">var</span> model = onlineBinaryClassification({
    <span class="hljs-string">'loss'</span>: <span class="hljs-string">'modifiedHuber'</span>,
    <span class="hljs-string">'lambda'</span>: <span class="hljs-number">1e-4</span>
});
</code></pre>
<p>The <code>learningRate</code> decides how fast or slow the weights will be updated towards the optimal weights. Let <code>i</code> denote the current iteration of the algorithm (i.e. the number of data points having arrived). The possible learning rates are:</p>
<table>
<thead>
<tr>
<th align="center">Option</th>
<th align="center">Definition</th>
</tr>
</thead>
<tbody>
<tr>
<td align="center">basic (default)</td>
<td align="center">1000.0 / ( i + 1000.0 )</td>
</tr>
<tr>
<td align="center">constant</td>
<td align="center">eta0</td>
</tr>
<tr>
<td align="center">pegasos</td>
<td align="center">1.0 / ( lambda * i )</td>
</tr>
</tbody>
</table>
<p>The used loss function is specified via the <code>loss</code> option. The available options are:</p>
<ul>
<li><strong>hinge</strong>: hinge loss corresponding to a soft-margin linear Support Vector Machine (SVM), which can handle non linearly separable data.</li>
<li><strong>log</strong>: logistic loss. Corresponds to Logistic Regression.</li>
<li><strong>modifiedHuber</strong>: Huber loss variant for classification. </li>
<li><strong>perceptron</strong>: hinge loss without a margin. Corresponds to the original Perceptron by Rosenblatt.</li>
<li><strong>squaredHinge</strong>: squared hinge loss SVM (L2-SVM).</li>
</ul>
<p>The <code>lambda</code> parameter determines the amount of shrinkage inflicted on the model coefficients:</p>
<pre><code class="hljs language-javascript"><span class="hljs-keyword">var</span> createRandom = <span class="hljs-built_in">require</span>( <span class="hljs-string">'@stdlib/random/base/randu'</span> ).factory;

<span class="hljs-keyword">var</span> model;
<span class="hljs-keyword">var</span> coefs;
<span class="hljs-keyword">var</span> opts;
<span class="hljs-keyword">var</span> rand;
<span class="hljs-keyword">var</span> x1;
<span class="hljs-keyword">var</span> x2;
<span class="hljs-keyword">var</span> i;
<span class="hljs-keyword">var</span> y;

opts = {
    <span class="hljs-string">'seed'</span>: <span class="hljs-number">23</span>
};
rand = createRandom( opts );

model = onlineBinaryClassification({
    <span class="hljs-string">'lambda'</span>: <span class="hljs-number">1e-6</span>,
    <span class="hljs-string">'loss'</span>: <span class="hljs-string">'perceptron'</span>
});

<span class="hljs-keyword">for</span> ( i = <span class="hljs-number">0</span>; i &#x3C; <span class="hljs-number">10000</span>; i++ ) {
    x1 = rand();
    x2 = rand();
    y = ( x1 + x2 > <span class="hljs-number">1.0</span> ) ? +<span class="hljs-number">1</span> : <span class="hljs-number">-1</span>;
    model.update( [ x1, x2 ], y );
}

coefs = model.coefs;
<span class="hljs-comment">// returns [ ~4.205, ~4.186, ~-4.206 ]</span>

rand = createRandom( opts );
model = onlineBinaryClassification({
    <span class="hljs-string">'lambda'</span>: <span class="hljs-number">1e-2</span>
});

<span class="hljs-keyword">for</span> ( i = <span class="hljs-number">0</span>; i &#x3C; <span class="hljs-number">10000</span>; i++ ) {
    x1 = rand();
    x2 = rand();
    y = ( x1 + x2 > <span class="hljs-number">1.0</span> ) ? +<span class="hljs-number">1</span> : <span class="hljs-number">-1</span>;
    model.update( [ x1, x2 ], y );
}

coefs = model.coefs;
<span class="hljs-comment">// returns [ ~2.675, ~2.616, ~-2.375 ]</span>
</code></pre>
<p>Higher values of <code>lambda</code> reduce the variance of the model coefficient estimates at the expense of introducing bias.</p>
<p>By default, the model contains an <code>intercept</code> term. To omit the <code>intercept</code>, set the corresponding option to <code>false</code>:</p>
<pre><code class="hljs language-javascript"><span class="hljs-keyword">var</span> model = onlineBinaryClassification({
    <span class="hljs-string">'intercept'</span>: <span class="hljs-literal">false</span>
});
model.update( [ <span class="hljs-number">1.4</span>, <span class="hljs-number">0.5</span> ], <span class="hljs-number">1</span> );

<span class="hljs-keyword">var</span> dim = model.coefs.length;
<span class="hljs-comment">// returns 2</span>

model = onlineBinaryClassification();
model.update( [ <span class="hljs-number">1.4</span>, <span class="hljs-number">0.5</span> ], <span class="hljs-number">-1</span> );

dim = model.coefs.length;
<span class="hljs-comment">// returns 3</span>
</code></pre>
<p>If <code>intercept</code> is <code>true</code>, an element equal to one is implicitly added to each <code>x</code> vector. Hence, this module performs regularization of the intercept term.</p>
<h4 id="model">Model</h4>
<p>Returned models have the following properties and methods...</p>
<h4 id="modelupdate-x-y-">model.update( x, y )</h4>
<p>Update the model coefficients in light of incoming data. <code>y</code> has to be either <code>+1</code> or <code>-1</code>, <code>x</code> a <code>numeric array</code> of predictors. The number of predictors is decided upon first invocation of this method. All subsequent calls must supply <code>x</code> vectors of the same dimensionality.</p>
<!-- run-disable -->
<pre><code class="hljs language-javascript">model.update( [ <span class="hljs-number">1.0</span>, <span class="hljs-number">0.0</span> ], <span class="hljs-number">-1</span> );
</code></pre>
<h4 id="modelpredict-x-type-">model.predict( x[, type] )</h4>
<p>Calculates the linear predictor for a given feature vector <code>x</code>. Given <code>x = [x_0, x_1, ...]</code> and model coefficients <code>c = [c_0, c_1, ...]</code>, the linear predictor is equal to <code>x_0*c_0 + x_1*c_1 + ... + c_intercept</code>. For the logistic and modified Huber loss functions, supply <code>probability</code> for the <code>type</code> parameter to retrieve prediction probabilities.</p>
<!-- run-disable -->
<pre><code class="hljs language-javascript"><span class="hljs-keyword">var</span> lp = model.predict( [ <span class="hljs-number">0.5</span>, <span class="hljs-number">2.0</span> ] );
<span class="hljs-comment">// returns &#x3C;number></span>

<span class="hljs-keyword">var</span> phat = model.predict( [ <span class="hljs-number">0.5</span>, <span class="hljs-number">2.0</span> ], <span class="hljs-string">'probability'</span> );
<span class="hljs-comment">// returns &#x3C;number></span>
</code></pre>
<h4 id="modelcoefs">model.coefs</h4>
<p>Getter for the model coefficients / feature weights stored in an <code>array</code>. The coefficients are ordered as <code>[c_0, c_1,..., c_intercept]</code>, where <code>c_0</code> corresponds to the first feature in <code>x</code> and so on.</p>
<!-- run-disable -->
<pre><code class="hljs language-javascript"><span class="hljs-keyword">var</span> coefs = model.coefs;
<span class="hljs-comment">// returns &#x3C;Array></span>
</code></pre>
</section>
<!-- /.usage -->
<section class="notes">
<h2 id="notes">Notes</h2>
<ul>
<li>Stochastic gradient descent is sensitive to the scaling of the features. One is best advised to either scale each attribute to <code>[0,1]</code> or <code>[-1,1]</code> or to transform them into z-scores with zero mean and unit variance. One should keep in mind that the same scaling has to be applied to test vectors in order to obtain accurate predictions.</li>
</ul>
</section>
<!-- /.notes -->
<section class="examples">
<h2 id="examples">Examples</h2>
<!-- eslint-disable id-length -->
<!-- eslint no-undef: "error" -->
<pre><code class="hljs language-javascript"><span class="hljs-keyword">var</span> binomial = <span class="hljs-built_in">require</span>( <span class="hljs-string">'@stdlib/random/base/binomial'</span> );
<span class="hljs-keyword">var</span> normal = <span class="hljs-built_in">require</span>( <span class="hljs-string">'@stdlib/random/base/normal'</span> );
<span class="hljs-keyword">var</span> exp = <span class="hljs-built_in">require</span>( <span class="hljs-string">'@stdlib/math/base/special/exp'</span> );
<span class="hljs-keyword">var</span> onlineBinaryClassification = <span class="hljs-built_in">require</span>( <span class="hljs-string">'@stdlib/ml/online-binary-classification'</span> );

<span class="hljs-keyword">var</span> phat;
<span class="hljs-keyword">var</span> lp;
<span class="hljs-keyword">var</span> x1;
<span class="hljs-keyword">var</span> x2;
<span class="hljs-keyword">var</span> y;
<span class="hljs-keyword">var</span> i;

<span class="hljs-comment">// Create model:</span>
<span class="hljs-keyword">var</span> model = onlineBinaryClassification({
    <span class="hljs-string">'lambda'</span>: <span class="hljs-number">1e-3</span>,
    <span class="hljs-string">'loss'</span>: <span class="hljs-string">'log'</span>,
    <span class="hljs-string">'intercept'</span>: <span class="hljs-literal">true</span>
});

<span class="hljs-comment">// Update model as data comes in...</span>
<span class="hljs-keyword">for</span> ( i = <span class="hljs-number">0</span>; i &#x3C; <span class="hljs-number">10000</span>; i++ ) {
    x1 = normal( <span class="hljs-number">0.0</span>, <span class="hljs-number">1.0</span> );
    x2 = normal( <span class="hljs-number">0.0</span>, <span class="hljs-number">1.0</span> );
    lp = (<span class="hljs-number">3.0</span> * x1) - (<span class="hljs-number">2.0</span> * x2) + <span class="hljs-number">1.0</span>;
    phat = <span class="hljs-number">1.0</span> / ( <span class="hljs-number">1.0</span> + exp( -lp ) );
    y = ( binomial( <span class="hljs-number">1</span>, phat ) ) ? <span class="hljs-number">1.0</span> : <span class="hljs-number">-1.0</span>;
    model.update( [ x1, x2 ], y );
}

<span class="hljs-comment">// Extract model coefficients:</span>
<span class="hljs-built_in">console</span>.log( model.coefs );

<span class="hljs-comment">// Predict new observations:</span>
<span class="hljs-built_in">console</span>.log( <span class="hljs-string">'Pr(Y=1)_hat = %d; x1 = %d; x2 = %d'</span>, model.predict( [<span class="hljs-number">0.9</span>, <span class="hljs-number">0.1</span>], <span class="hljs-string">'probability'</span> ), <span class="hljs-number">0.9</span>, <span class="hljs-number">0.1</span> );
<span class="hljs-built_in">console</span>.log( <span class="hljs-string">'y_hat = %d; x1 = %d; x2 = %d'</span>, model.predict( [<span class="hljs-number">0.1</span>, <span class="hljs-number">0.9</span>], <span class="hljs-string">'link'</span> ), <span class="hljs-number">0.1</span>, <span class="hljs-number">0.9</span> );
<span class="hljs-built_in">console</span>.log( <span class="hljs-string">'y_hat = %d; x1 = %d; x2 = %d'</span>, model.predict( [<span class="hljs-number">0.9</span>, <span class="hljs-number">0.9</span>], <span class="hljs-string">'link'</span> ), <span class="hljs-number">0.9</span>, <span class="hljs-number">0.9</span> );
</code></pre>
</section>
<!-- /.examples -->
<section class="links">
</section>
<!-- /.links -->
